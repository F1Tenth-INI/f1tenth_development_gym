library: "TF" # TF or Pytorch
modeling:
  NET_NAME: "GRU-128H1-128H2-128H3"
paths:
  # PATH HAS TO END WITH A SOLIDUS ("/") CHARACTER
  path_to_experiment: ""
  PATH_TO_EXPERIMENT_FOLDERS: "./SI_Toolkit_ASF/Experiments/04_08_RCA1_noise/" # Path where the experiments data is stored
  DATA_FOLDER: "Recordings"

training_default:
  AUGMENT_DATA: False

  ## translation_invariant_variables: ['pose_x', 'pose_y']
  translation_invariant_variables: []

  state_inputs: []

  control_inputs: [
      "WYPT_REL_X(30)",
      "WYPT_REL_Y(30)",
      "WYPT_VX(30)",
      "angular_vel_z",
      "linear_vel_x",
      "linear_vel_y",
      "steering_angle",
      # "mu",
      # "angular_control_calculated_-1",
      # "translational_control_calculated_-1",
    ]

  

  # state_inputs: []
  # control_inputs: lidar_data + waypoints_x + waypoints_y + waypoints_vx + vel_and_angle

  setpoint_inputs: []
  outputs:
    ["angular_control_new","translational_control_new"] # "mu"

  EPOCHS: 50
  BATCH_SIZE: 16
  SEED: 1873
  LR:
    INITIAL: 1.0e-3
    REDUCE_LR_ON_PLATEAU: True
    ACTIVATED: True
    DECREASE_FACTOR: 0.316 # Factor to reduce learning rate by (0.316 = sqrt(0.1))
    PATIENCE: 1
    MINIMAL: 1.0e-5
    MIN_DELTA: 0.00
  VALIDATE_ALSO_ON_TRAINING_SET: False
  LOSS_MODE: 'squared'
  WASH_OUT_LEN: 20
  POST_WASH_OUT_LEN: 300
  ON_FLY_DATA_GENERATION: False
  NORMALIZE: True
  SHIFT_LABELS: 0 # for k, as a label to row i is taken row i+k
  USE_NNI: False # Decide if you want to use NNI package
  CONSTRUCT_NETWORK: "with cells" # Matters only for Pytorch

  ### Lidar Data: from 0 to 1080 on 270 Degrees (4 ranges per degree). Example; scan exactly 180 Degrees by setting lower_bound=180 and upper_bound=900.
  # Depending on number of Lidar points listed in state input, an even distribution of input scans between the two bounds is selected and fed to the network.
  #ToDo instead of listing all Lidar Points, one just writes how many and the state input vector is generated automatically
  upper_bound: 880
  lower_bound: 200
  PLOT_WEIGHTS_DISTRIBUTION: false # Calculate histograms of weights and biases and activations, take long time

REGULARIZATION:
  ACTIVATED: False
QUANTIZATION: # Not implemented yet
  ACTIVATED: False
  ACTIVATION:
    bits: 6
  KERNEL:
    bits: 11
    integer: 6
    symmetric: True
  BIAS:
    bits: 11
    integer: 6
    symmetric: True
  RECURRENT:
    bits: 11
    integer: 6
    symmetric: True
PRUNING: # TF only for the moment
  ACTIVATED: False
  PRUNING_PARAMS:
    PRUNING_SCHEDULE: "CONSTANT_SPARSITY"
  PRUNING_SCHEDULES:
    CONSTANT_SPARSITY:
      target_sparsity: 0.75
      begin_step_in_epochs: 1.0 # fraction of epoch allowed
      end_step_in_training_fraction: 1.0
      frequency_per_epoch: 100.0 # fraction of epoch allowed
    POLYNOMIAL_DECAY:
      initial_sparsity: 0.0
      final_sparsity: 0.75
      begin_step_in_epochs: 1.0 # fraction of epoch allowed
      end_step_in_training_fraction: 0.8
      power: 3.0
      frequency_per_epoch: 1000 # fraction of epoch allowed

FILTERS: False

CONFIG_SERIES_MODIFICATION:
  NOISE_LEVEL:
    FEATURES: 1.0